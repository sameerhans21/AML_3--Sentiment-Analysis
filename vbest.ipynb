{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tweet sentiment analysis\nDuring this challenge, we tried to determine whether a tweet is a positive, negative or neutral message. For this purpose, we implemented different models. We tried a few basic models as well as a few advanced ones. After implementation, we compared their results and selected the best performing one.","metadata":{}},{"cell_type":"markdown","source":"### Summary :    \n> __1. Data Preparation__ \n\n> __2. Bert Transformer__\n\n> __3. Bag of Words__ \n\n> __4. Word To Vec__ ","metadata":{}},{"cell_type":"code","source":"import torch\n\nif torch.cuda.is_available():       \n    device = torch.device(\"cuda\")\n    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n    print('Device name:', torch.cuda.get_device_name(0))\n\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:05:21.558838Z","iopub.execute_input":"2021-05-31T18:05:21.559257Z","iopub.status.idle":"2021-05-31T18:05:21.566114Z","shell.execute_reply.started":"2021-05-31T18:05:21.559222Z","shell.execute_reply":"2021-05-31T18:05:21.564907Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: \n#               https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# plotting\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import MaxNLocator\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\n# general NLP preprocessing and basic tools\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\n# train/test split\nfrom sklearn.model_selection import train_test_split\n# basic machine learning models\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\n# our evaluation metric for sentiment classification\nfrom sklearn.metrics import fbeta_score\n\n# Don't print the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T18:11:11.632036Z","iopub.execute_input":"2021-05-31T18:11:11.632389Z","iopub.status.idle":"2021-05-31T18:11:11.641554Z","shell.execute_reply.started":"2021-05-31T18:11:11.632358Z","shell.execute_reply":"2021-05-31T18:11:11.640356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Data Preparation \n### a. Loading the data","metadata":{}},{"cell_type":"code","source":"train_data_path='/kaggle/input/eurecom-aml-2021-challenge-3/train.csv'\ntest_data_path='/kaggle/input/eurecom-aml-2021-challenge-3/test.csv'\n\ntrain_df = pd.read_csv(train_data_path);\ntest_df = pd.read_csv(test_data_path);\n\n#train_df = train_df.loc[:1000]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:15.356858Z","iopub.execute_input":"2021-05-31T18:11:15.357263Z","iopub.status.idle":"2021-05-31T18:11:15.444189Z","shell.execute_reply.started":"2021-05-31T18:11:15.357223Z","shell.execute_reply":"2021-05-31T18:11:15.44317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### b. Data inspection","metadata":{}},{"cell_type":"code","source":"print(\"len(train_df) =\",len(train_df),\n    \"\\nlen(test_df) =\",len(test_df),\n    \"\\nlen(train_df) + len(test_df) =\",len(train_df)+len(test_df))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:18.040808Z","iopub.execute_input":"2021-05-31T18:11:18.041168Z","iopub.status.idle":"2021-05-31T18:11:18.053559Z","shell.execute_reply.started":"2021-05-31T18:11:18.041137Z","shell.execute_reply":"2021-05-31T18:11:18.052431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:21.294671Z","iopub.execute_input":"2021-05-31T18:11:21.29504Z","iopub.status.idle":"2021-05-31T18:11:21.305165Z","shell.execute_reply.started":"2021-05-31T18:11:21.294995Z","shell.execute_reply":"2021-05-31T18:11:21.304347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:24.45978Z","iopub.execute_input":"2021-05-31T18:11:24.460132Z","iopub.status.idle":"2021-05-31T18:11:24.469691Z","shell.execute_reply.started":"2021-05-31T18:11:24.460101Z","shell.execute_reply":"2021-05-31T18:11:24.468883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### c. Data preprocessing","metadata":{}},{"cell_type":"code","source":"def missing_zero_values_table(df,df_name):\n    '''\n    Inputs:\n        df: pandas table\n        df_name: string of the pandas table name\n    Output:\n        \"df_name has columns_nb columns and rows_nb Rows. There are columns_nb columns that have missing values.\"\n    '''\n    zero_val = (df == 0.00).astype(int).sum(axis=0)\n    mis_val = df.isnull().sum()\n    mis_val_percent = 100 * df.isnull().sum() / len(df)\n    mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n    mz_table = mz_table.rename(\n    columns = {0 : 'Zero Values', 1 : 'Missing Values', 2 : '% of Total Values'})\n    mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n    mz_table['% Total Zero Missing Values'] = 100 * mz_table['Total Zero Missing Values'] / len(df)\n    mz_table['Data Type'] = df.dtypes\n    mz_table = mz_table[mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n    print (df_name + \" has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"      \n        \"There are \" + str(mz_table.shape[0]) + \" columns that have missing values.\")\n    return mz_table\n    \nmissing_zero_values_table(train_df,\"train_df\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:28.037988Z","iopub.execute_input":"2021-05-31T18:11:28.038337Z","iopub.status.idle":"2021-05-31T18:11:28.091709Z","shell.execute_reply.started":"2021-05-31T18:11:28.038309Z","shell.execute_reply":"2021-05-31T18:11:28.090721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We start off by **converting the labels to numbers**. This is a requirement for the submission and numerical inputs are generally more compatible with machine learning libraries.","metadata":{}},{"cell_type":"code","source":"# pb with label \"-1\" for transformer !\n# have to reput the convenient label for the submission !\n# (to be in accordance with the test labels)\npositive_label, neutral_label, negative_label = 2,1,0\ntarget_conversion = {\n    'neutral': neutral_label,\n    'positive': positive_label,\n    'negative': negative_label\n}\n\ntrain_df['target'] = train_df['sentiment'].map(target_conversion)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:31.683933Z","iopub.execute_input":"2021-05-31T18:11:31.684281Z","iopub.status.idle":"2021-05-31T18:11:31.692518Z","shell.execute_reply.started":"2021-05-31T18:11:31.68425Z","shell.execute_reply":"2021-05-31T18:11:31.691631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Target distribution ","metadata":{}},{"cell_type":"code","source":"import matplotlib.patches as mpatches\nfig, ax= plt.subplots(figsize =(3,3))\n\nax = sns.countplot(x='target', data=train_df, palette=['#DC143C',\"#FFD700\",\"#32CD32\"]);\nfor p in ax.patches:\n    ax.annotate(p.get_height(), (p.get_x()+0.16, p.get_height()/2.2))\n\npatch1 = mpatches.Patch(color='#DC143C', label='Negative')\npatch2 = mpatches.Patch(color=\"#FFD700\", label='Neutral')\npatch3 = mpatches.Patch(color=\"#32CD32\", label='Positive')\n\nplt.legend(handles=[patch1, patch2, patch3], \n           bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\nplt.title(\"Distribution of the labels\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:34.925825Z","iopub.execute_input":"2021-05-31T18:11:34.926155Z","iopub.status.idle":"2021-05-31T18:11:35.076786Z","shell.execute_reply.started":"2021-05-31T18:11:34.926125Z","shell.execute_reply":"2021-05-31T18:11:35.075839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distribution is relatively well-balanced.\n\nData cleaning has already been done with the \"selected_text\" columns, but we can still improve it.","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS , ImageColorGenerator\n\noriginal_column = 'selected_text' ##### COLUMN TO BE PREPROCESSED (\"text\" or \"selected_text\") !!!! ####\n\n# Start with one review:\ndf_positive = train_df[train_df['target']==positive_label]\ndf_neutral = train_df[train_df['target']==neutral_label]\ndf_negative = train_df[train_df['target']==negative_label]\ntweet_all = \" \".join(review for review in train_df[original_column])\ntweet_positive = \" \".join(review for review in df_positive[original_column])\ntweet_neutral = \" \".join(review for review in df_neutral[original_column])\ntweet_negative = \" \".join(review for review in df_negative[original_column])\n\nfig, ax = plt.subplots(4, 1, figsize  = (30,30))\n# Create and generate a word cloud image:\nwordcloud_aLL = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_all)\nwordcloud_positive = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_positive)\nwordcloud_neutral = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_neutral)\nwordcloud_negative = WordCloud(max_font_size=50, max_words=100, background_color=\"white\").generate(tweet_negative)\n\n# Display the generated image:\nax[0].imshow(wordcloud_aLL, interpolation='bilinear')\nax[0].set_title('All Tweets', fontsize=30, pad=25)\nax[0].axis('off')\nax[1].imshow(wordcloud_positive, interpolation='bilinear')\nax[1].set_title('Tweets under positive Class',fontsize=30, pad=25)\nax[1].axis('off')\nax[2].imshow(wordcloud_neutral, interpolation='bilinear')\nax[2].set_title('Tweets under neutral Class',fontsize=30, pad=25)\nax[2].axis('off')\nax[3].imshow(wordcloud_negative, interpolation='bilinear')\nax[3].set_title('Tweets under negative Class',fontsize=30, pad=25)\nax[3].axis('off')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:38.45806Z","iopub.execute_input":"2021-05-31T18:11:38.458413Z","iopub.status.idle":"2021-05-31T18:11:41.297727Z","shell.execute_reply.started":"2021-05-31T18:11:38.458383Z","shell.execute_reply":"2021-05-31T18:11:41.296831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d. Data Cleaning\n\n#### d.1 Remove punctuations","metadata":{}},{"cell_type":"code","source":"import string\ns = string.punctuation\nprint(s)\ns = s.translate({ord(i): None for i in '@'})\nprint(s)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:46.375858Z","iopub.execute_input":"2021-05-31T18:11:46.376354Z","iopub.status.idle":"2021-05-31T18:11:46.383274Z","shell.execute_reply.started":"2021-05-31T18:11:46.376316Z","shell.execute_reply":"2021-05-31T18:11:46.382337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import string\npunctuation_string = string.punctuation\npunctuation_string = punctuation_string.translate({ord(i): None for i in '@'})\n\nimport re\ndef remove_punct(text,punctuation_string):\n    text  = \"\".join([char for char in text if char not in punctuation_string])\n    text = re.sub('[0-9]+', '', text)\n    return text\n\nhead_nb = 10 # nb of lines to print when using pd.head(head_nb)\n\ntrain_df['Tweet_punct'] = train_df[original_column].apply(lambda x: remove_punct(x,punctuation_string))\ntrain_df.head(head_nb)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:50.915841Z","iopub.execute_input":"2021-05-31T18:11:50.916198Z","iopub.status.idle":"2021-05-31T18:11:51.092527Z","shell.execute_reply.started":"2021-05-31T18:11:50.916168Z","shell.execute_reply":"2021-05-31T18:11:51.091575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d.2 Tokenization","metadata":{}},{"cell_type":"code","source":"def tokenization(text):\n    text = re.split('\\W+', text)\n    return text\n\ntrain_df['Tweet_tokenized'] = train_df['Tweet_punct'].apply(lambda x: tokenization(x.lower()))\ntrain_df.head(head_nb)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:54.543665Z","iopub.execute_input":"2021-05-31T18:11:54.544003Z","iopub.status.idle":"2021-05-31T18:11:54.676435Z","shell.execute_reply.started":"2021-05-31T18:11:54.543972Z","shell.execute_reply":"2021-05-31T18:11:54.675648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d.3 Word Replacement","metadata":{}},{"cell_type":"code","source":"replaced_words = [(\"hmmyou\",\"\"),(\"sry\",\"sorry\"),(\"inlove\",\"in love\"),(\"thats\",\"\"),(\"wanna\",\"\"),\n                  (\"soo\",\"so\"),(\"inlove\",\"in love\"),(\"amazingwell\",\"amazing well\"),\n                  (\"messagesorry\",\"message sorry\"),(\"½\",\"\"),(\"tomorrowneed\",\"tomorrow need\"),\n                  (\"tomorrowis\",\"tomorrow is\"),(\"amusedtime\",\"amused time\"),(\"weekendor\",\"weekend or\"),\n                  (\"competitionhope\",\"competition hope\"),(\"partypicnic\",\"party picnic\"),\n                  (\"ahmazing\",\"amazing\"),(\"wont\",\"will not\"),(\"didnt\",\"did not\"),(\"dont\",\"do not\"),\n                  (\"lookin\",\"looking\"),(\"u\",\"you\"),(\"youre\",\"you are\"),(\"nite\",\"night\"),(\"isnt\",\"is not\"),\n                  (\"k\",\"\"),(\"is\",\"\"),(\"doesnt\",\"does not\"),(\"l\",\"\"),(\"x\",\"\"),(\"c\",\"\"),(\"ur\",\"your\"),\n                  (\"e\",\"\"),(\"yall\",\"you all\"),(\"he\",\"\"),(\"us\",\"\"),(\"okim\",\"ok i am\"),(\"jealousi\",\"jealous\"),\n                  (\"srry\",\"sorry\"),(\"itll\",\"it will\"),(\"vs\",\"\"),(\"weeknend\",\"weekend\"),(\"w\",\"\"),\n                  (\"yr\",\"year\"),(\"youve\",\"you have\"),(\"havent\",\"have not\"),(\"iï\",\"\"),(\"gonna\",\"going to\"),\n                  (\"gimme\",\"give me\"),(\"ti\",\"\"),(\"ta\",\"\"),(\"thru\",\"through\"),(\"th\",\"\"),(\"imma\",\"i am going to\"),\n                  (\"wasnt\",\"was not\"),(\"arent\",\"are not\"), (\"bff\",\"best friend forever\"),(\"sometimesdid\",\"sometimes did\"),\n                  (\"waitt\",\"wait\"),(\"bday\",\"birthday\"),(\"toobut\",\"too but\"),(\"showerand\",\"shower and\"),\n                  (\"innit\",\"is not it\"),(\"surgury\",\"surgery\"),(\"soproudofyo\",\"so proud of you\"),(\"p\",\"\"),\n                  (\"couldnt\",\"could not\"),(\"dohforgot\",\"forgot\"),(\"rih\",\"right\"),(\"b\",\"\"),(\"bmovie\",\"movie\"),\n                  (\"pleaseyour\",\"please your\"),(\"tonite\",\"tonight\"),(\"grea\",\"great\"),(\"se\",\"\"),(\"soonso\",\"soon so\"),\n                  (\"gettin\",\"getting\"),(\"blowin\",\"blowing\"),(\"coz\",\"because\"),(\"thanks\",\"thank\"),(\"st\",\"\"),(\"rd\",\"\"),\n                  (\"gtta\",\"have got to\"),(\"gotta\",\"have got to\"),(\"anythingwondering\",\"anything wondering\"),\n                  (\"annoyedy\",\"annoyed\"),(\"p\",\"\"),(\"beatiful\",\"beautiful\"),(\"multitaskin\",\"multitasking\"),\n                  (\"nightmornin\",\"night morning\"),(\"thankyou\",\"thank you\"),(\"iloveyoutwoooo\",\"i love you two\"),\n                  (\"tmwr\",\"tomorrow\"),(\"wordslooks\",\"words looks\"),(\"ima\",\"i am going to\"),(\"liek\",\"like\"),(\"mr\",\"\"),\n                  (\"allnighter\",\"all nighter\"),(\"tho\",\"though\"),(\"ed\",\"\"),(\"fyou\",\"\"),(\"footlong\",\"foot long\"),\n                  (\"placepiggy\",\"place piggy\"),(\"semiflaky\",\"semi flaky\"),(\"gona\",\"going to\"),(\"tmr\",\"tomorrow\"),\n                  (\"ppl\",\"people\"),(\"n\",\"\"),(\"dis\",\"this\"),(\"dun\",\"done\"),(\"houseee\",\"house\"),(\"havee\",\"have\"),\n                  (\"studyingwhew\",\"studying whew\"),(\"awwyoure\",\"aww you are\"),(\"softyi\",\"softy\"),\n                  (\"weddingyou\",\"wedding you\"),(\"hassnt\",\"has not\"),(\"lowerleft\",\"lower left\"),(\"anywayss\",\"anyway\"),\n                  (\"adoarble\",\"adorable\"),(\"blogyeahhhh\",\"blog yeahhhh\"),(\"billsim\",\"bills i am\"),(\"ps\",\"\"),\n                  (\"cheescake\",\"cheesecake\"),(\"morningafternoonnight\",\"morning after noon night\"),\n                  (\"allstudying\",\"all studying\"),(\"ofcoooursee\",\"of course\"),(\"jst\",\"just\"),(\"shes\",\"she is\"),\n                  (\"sonicswhich\",\"sonics which\"),(\"ouchwaited\",\"ouch waited\"),(\"itll\",\"it will\"),(\"orreply\",\"or reply\"),\n                  (\"somethin\",\"something\"),(\"fridayand\",\"friday and\"),(\"outta\",\"out of\"),(\"herenever\",\"here never\")\n                 ] \n\ndef replace_words(text,replaced_words):\n    ind = -1 \n    for word in text:\n        ind +=1\n        for k in range(len(replaced_words)):\n            if word == replaced_words[k][0]:\n                text[ind] = replaced_words[k][1]\n            elif \"http\" in word:\n                text[ind] = \"\"\n            elif \"@\" in word:\n                text[ind] = \"\"\n            elif \"www.\" in word:\n                text[ind] = \"\"\n            elif \"Â\" in word: \n                text[ind] = \"\"\n            elif \"Ã\" in word: \n                text[ind] = \"\"\n            elif \"½\" in word:\n                text[ind] = \"\"\n    return text\n\ntrain_df['Tweet_tokenized'] = train_df['Tweet_tokenized'].apply(lambda x: replace_words(x,replaced_words))\ntrain_df.head(head_nb)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:11:58.790508Z","iopub.execute_input":"2021-05-31T18:11:58.790824Z","iopub.status.idle":"2021-05-31T18:12:05.140842Z","shell.execute_reply.started":"2021-05-31T18:11:58.790795Z","shell.execute_reply":"2021-05-31T18:12:05.140054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d.4 Remove stopwords","metadata":{}},{"cell_type":"code","source":"stopword = nltk.corpus.stopwords.words('english')\nprint(\"stopword:\\n\",stopword)\nprint(\"\\n\\n There are some words that we want to keep, for example 'no', 'nor','not'\\n\")\nwords_to_keep = [\"not\",\"no\",\"nor\"]\nstopword = [elem for elem in stopword if not elem in words_to_keep]\nstopword.extend([\"im\",\"theyre\",\"ive\",\"p\",\"alot\",\"er\",\"\"]) # Other stopwords to remove\nprint(\"stopword:\\n\",stopword,\"\\n\")\n\ndef remove_stopwords(text,stopword):\n    text = [word for word in text if word not in stopword]\n    return text\n    \ntrain_df['Tweet_nonstop'] = train_df['Tweet_tokenized'].apply(lambda x: remove_stopwords(x,stopword))\npd.options.display.max_rows = 4000\ntrain_df.head(head_nb)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:05.142329Z","iopub.execute_input":"2021-05-31T18:12:05.142679Z","iopub.status.idle":"2021-05-31T18:12:05.430034Z","shell.execute_reply.started":"2021-05-31T18:12:05.142644Z","shell.execute_reply":"2021-05-31T18:12:05.429078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d.5 Stemming/Lammetization - Tranforming any form of a word to its root word","metadata":{}},{"cell_type":"code","source":"stemmed_or_lemmatized = \"Tweet_lemmatized\" # \"Tweet_lemmatized\" OR \"Tweet_stemmed\"","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:06.991758Z","iopub.execute_input":"2021-05-31T18:12:06.992103Z","iopub.status.idle":"2021-05-31T18:12:06.997887Z","shell.execute_reply.started":"2021-05-31T18:12:06.992072Z","shell.execute_reply":"2021-05-31T18:12:06.994922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d.5.a Stemming","metadata":{}},{"cell_type":"code","source":"ps = nltk.PorterStemmer()\n\ndef stemming(text):\n    text = [ps.stem(word) for word in text]\n    return text\n\ntrain_df['Tweet_stemmed'] = train_df['Tweet_nonstop'].apply(lambda x: stemming(x))\ntrain_df.head(head_nb)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:09.252827Z","iopub.execute_input":"2021-05-31T18:12:09.253227Z","iopub.status.idle":"2021-05-31T18:12:11.90233Z","shell.execute_reply.started":"2021-05-31T18:12:09.253194Z","shell.execute_reply":"2021-05-31T18:12:11.900985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### d.5.b Lemmatization","metadata":{}},{"cell_type":"code","source":"wn = nltk.WordNetLemmatizer()\n\ndef lemmatizer(text):\n    text = [wn.lemmatize(word) for word in text]\n    return text\n\ntrain_df['Tweet_lemmatized'] = train_df[\"Tweet_nonstop\"].apply(lambda x: lemmatizer(x))\ntrain_df.head(head_nb)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:15.375026Z","iopub.execute_input":"2021-05-31T18:12:15.375391Z","iopub.status.idle":"2021-05-31T18:12:15.869613Z","shell.execute_reply.started":"2021-05-31T18:12:15.375359Z","shell.execute_reply":"2021-05-31T18:12:15.868546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, we change the type of the Tweet_lemmatized column from list to string (required for the rest).","metadata":{}},{"cell_type":"code","source":"train_df['Tweet_lemmatized'] = train_df[stemmed_or_lemmatized].apply(lambda x: ' '.join(str(e) for e in x))\ntrain_df.head(head_nb)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:20.069841Z","iopub.execute_input":"2021-05-31T18:12:20.070194Z","iopub.status.idle":"2021-05-31T18:12:20.138481Z","shell.execute_reply.started":"2021-05-31T18:12:20.070165Z","shell.execute_reply":"2021-05-31T18:12:20.137499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_scruting = pd.DataFrame()\ntrain_scruting['selected_text'] = train_df['selected_text']\ntrain_scruting['Tweet_lemmatized'] = train_df['Tweet_lemmatized']\ntrain_scruting.to_csv('train_scruting.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:23.269859Z","iopub.execute_input":"2021-05-31T18:12:23.270204Z","iopub.status.idle":"2021-05-31T18:12:23.364661Z","shell.execute_reply.started":"2021-05-31T18:12:23.270175Z","shell.execute_reply":"2021-05-31T18:12:23.363859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### e . Tweet length","metadata":{}},{"cell_type":"code","source":"def plot_dist3(df, feature, title):\n    '''\n    Input:\n        df: [Pandas] Dataset\n        feature: [String] Column of tweets\n    '''\n    df['Character_Count'] = df[feature].apply(lambda x: len(str(x)))\n    feature = 'Character_Count'\n    # Creating a customized chart. and giving in figsize and everything.\n    fig = plt.figure(constrained_layout=True, figsize=(18, 8))\n    # Creating a grid of 3 cols and 3 rows.\n    grid = gridspec.GridSpec(ncols=3, nrows=3, figure=fig)\n\n    # Customizing the histogram grid.\n    ax1 = fig.add_subplot(grid[:2, :2])\n    # Set the title.\n    ax1.set_title('Histogram')\n    # plot the histogram.\n    sns.distplot(df.loc[:, feature],\n                 hist=True,\n                 kde=True,\n                 ax=ax1,\n                 color='#e74c3c')\n    ax1.set(ylabel='Frequency')\n    ax1.xaxis.set_major_locator(MaxNLocator(nbins=20))\n\n    # Customizing the ecdf_plot.\n    ax2 = fig.add_subplot(grid[2:, :2])\n    # Set the title.\n    ax2.set_title('Empirical CDF')\n    # Plotting the ecdf_Plot.\n    sns.distplot(df.loc[:, feature],\n                 ax=ax2,\n                 kde_kws={'cumulative': True},\n                 hist_kws={'cumulative': True},\n                 color='#e74c3c')\n    ax2.xaxis.set_major_locator(MaxNLocator(nbins=20))\n    ax2.set(ylabel='Cumulative Probability')\n\n    # Customizing the Box Plot.\n    ax3 = fig.add_subplot(grid[:, 2])\n    # Set title.\n    ax3.set_title('Box Plot')\n    # Plotting the box plot.\n    sns.boxplot(y=feature, data=df, ax=ax3, color='#e74c3c')\n    ax3.yaxis.set_major_locator(MaxNLocator(nbins=20))\n\n    plt.suptitle(f'{title}', fontsize=24)\n    \nplot_dist3(train_df, \"text\",'Characters per all Tweets for the column \"text\"')\nplot_dist3(train_df, \"Tweet_lemmatized\",'Characters per all Tweets for the column \"Tweet_lemmatized\"')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:26.228015Z","iopub.execute_input":"2021-05-31T18:12:26.228342Z","iopub.status.idle":"2021-05-31T18:12:29.580441Z","shell.execute_reply.started":"2021-05-31T18:12:26.228313Z","shell.execute_reply":"2021-05-31T18:12:29.579613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_word_number_histogram(textne, textpo, textng,column_name):\n    \n    \"\"\"A function for comparing word counts\"\"\"\n\n    fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(18, 6), sharey=True)\n    sns.distplot(textne.str.split().map(lambda x: len(x)), ax=axes[0], color='#e74c3c')\n    sns.distplot(textpo.str.split().map(lambda x: len(x)), ax=axes[1], color='#e74c3c')\n    sns.distplot(textng.str.split().map(lambda x: len(x)), ax=axes[2], color='#e74c3c')\n    \n    axes[0].set_xlabel('Word Count')\n    axes[0].set_title('neutral')\n    axes[1].set_xlabel('Word Count')\n    axes[1].set_title('positive')\n    axes[2].set_xlabel('Word Count')\n    axes[2].set_title('negative')\n    \n    fig.suptitle('Word counts in tweets for the column \"{}\"'.format(column_name), fontsize=24, va='baseline')\n    \n    fig.tight_layout()\n    \nfinal_column = 'Tweet_lemmatized'\nanalysed_column = 'target'\n    \nplot_word_number_histogram(train_df[train_df[analysed_column] == neutral_label][original_column],\n                           train_df[train_df[analysed_column] == positive_label][original_column],\n                           train_df[train_df[analysed_column] == negative_label][original_column],original_column)\n\nplot_word_number_histogram(train_df[train_df[analysed_column] == neutral_label][final_column],\n                           train_df[train_df[analysed_column] == positive_label][final_column],\n                           train_df[train_df[analysed_column] == negative_label][final_column],final_column)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:33.246215Z","iopub.execute_input":"2021-05-31T18:12:33.246548Z","iopub.status.idle":"2021-05-31T18:12:35.485705Z","shell.execute_reply.started":"2021-05-31T18:12:33.246514Z","shell.execute_reply":"2021-05-31T18:12:35.48488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_word_len_histogram(textne, textpo, textng, column_name):\n    \n    \"\"\"A function for comparing average word length\"\"\"\n    \n    fig, axes = plt.subplots(ncols=3, nrows=1, figsize=(18, 6), sharey=True)\n    sns.distplot(textne.str.split().apply(lambda x: [len(i) for i in x]).map(\n        lambda x: np.mean(x)),\n                 ax=axes[0], color='#e74c3c')\n    sns.distplot(textpo.str.split().apply(lambda x: [len(i) for i in x]).map(\n        lambda x: np.mean(x)),\n                 ax=axes[1], color='#e74c3c')\n    sns.distplot(textng.str.split().apply(lambda x: [len(i) for i in x]).map(\n        lambda x: np.mean(x)),\n                 ax=axes[2], color='#e74c3c')\n    \n    axes[0].set_xlabel('Word Count')\n    axes[0].set_ylabel('mean')\n    axes[0].set_title('neutral')\n    axes[1].set_xlabel('Word Count')\n    axes[1].set_title('positive')\n    axes[2].set_xlabel('Word Count')\n    axes[2].set_title('negative')\n    \n    fig.suptitle('Mean Word Lengths for the column \"{}\"'.format(column_name), fontsize=24, va='baseline')\n    fig.tight_layout()\n    \nplot_word_len_histogram(train_df[train_df[analysed_column] == neutral_label][original_column],\n                           train_df[train_df[analysed_column] == positive_label][original_column],\n                           train_df[train_df[analysed_column] == negative_label][original_column],original_column)\n    \nplot_word_len_histogram(train_df[train_df[analysed_column] == neutral_label][final_column],\n                           train_df[train_df[analysed_column] == positive_label][final_column],\n                           train_df[train_df[analysed_column] == negative_label][final_column],final_column)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:12:40.857955Z","iopub.execute_input":"2021-05-31T18:12:40.858283Z","iopub.status.idle":"2021-05-31T18:12:44.34214Z","shell.execute_reply.started":"2021-05-31T18:12:40.858252Z","shell.execute_reply":"2021-05-31T18:12:44.341079Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### f. N-gram","metadata":{}},{"cell_type":"markdown","source":"### f.1 Common unigrams for all tweets:","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nimport plotly.express as px\n\ndef top_most_common_words(dataset,column_name,top_nb,sentiment):\n    \"\"\"\n    Inputs:\n        Dataset: [Pandas]\n        Column_name: [String] The name of the column we are interesting with\n        sentiment: [String] \"all\", \"positive\", \"neutral\" or \"negative\"\n    \"\"\"\n    dataset['temp_list'] = dataset[column_name].apply(lambda x:str(x).split())\n    top = Counter([item for sublist in dataset['temp_list'] for item in sublist])\n    temp = pd.DataFrame(top.most_common(top_nb))\n    temp.columns = ['Common_words','count']\n    fig = px.bar(temp, x=\"count\", y=\"Common_words\",title='Common Words in {} for {} tweets'.format(column_name,sentiment), orientation='h', \n             width=700, height=700,color='Common_words',text='count')\n    return fig.show(renderer=\"notebook\")\n    \ntop_nb=25\n\ntop_most_common_words(train_df,original_column,top_nb,\"all\")\n\ntop_most_common_words(train_df,final_column,top_nb,\"all\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:13:09.150791Z","iopub.execute_input":"2021-05-31T18:13:09.151141Z","iopub.status.idle":"2021-05-31T18:13:09.812508Z","shell.execute_reply.started":"2021-05-31T18:13:09.151112Z","shell.execute_reply":"2021-05-31T18:13:09.811741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### f.2 Most common unigrams (1-gram):","metadata":{}},{"cell_type":"code","source":"top_most_common_words(train_df[train_df[analysed_column]==neutral_label],final_column,top_nb,\"neutral\")\ntop_most_common_words(train_df[train_df[analysed_column]==positive_label],final_column,top_nb,\"positive\")\ntop_most_common_words(train_df[train_df[analysed_column]==negative_label],final_column,top_nb,\"negative\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:13:25.862898Z","iopub.execute_input":"2021-05-31T18:13:25.863266Z","iopub.status.idle":"2021-05-31T18:13:26.779386Z","shell.execute_reply.started":"2021-05-31T18:13:25.863229Z","shell.execute_reply":"2021-05-31T18:13:26.778438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### f.3 Most common 2-grams:","metadata":{}},{"cell_type":"code","source":"import collections\nc=collections.Counter()\nfor i in train_df[\"Tweet_lemmatized\"]:\n  x = i.rstrip().split(\" \")\n  c.update(set(zip(x[:-1],x[1:])))\n    \n# c.most_common()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:13:48.680602Z","iopub.execute_input":"2021-05-31T18:13:48.68099Z","iopub.status.idle":"2021-05-31T18:13:48.790381Z","shell.execute_reply.started":"2021-05-31T18:13:48.680947Z","shell.execute_reply":"2021-05-31T18:13:48.789558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### f.4 Most common 3-grams:","metadata":{}},{"cell_type":"code","source":"c=collections.Counter()\nfor i in train_df[\"Tweet_lemmatized\"]:\n    x = i.rstrip().split(\" \")\n    c.update(set(zip(x[:-2],x[1:-1],x[2:])))\n    \n# c.most_common()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:14:01.819269Z","iopub.execute_input":"2021-05-31T18:14:01.819594Z","iopub.status.idle":"2021-05-31T18:14:01.92876Z","shell.execute_reply.started":"2021-05-31T18:14:01.819562Z","shell.execute_reply":"2021-05-31T18:14:01.927908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### g. Apply the preprocessing on the test df","metadata":{}},{"cell_type":"code","source":"test_df['Tweet_punct'] = test_df[original_column].apply(lambda x: remove_punct(x,punctuation_string))\ntest_df['Tweet_tokenized'] = test_df['Tweet_punct'].apply(lambda x: tokenization(x.lower()))\ntest_df['Tweet_tokenized'] = test_df['Tweet_tokenized'].apply(lambda x: replace_words(x,replaced_words))\ntest_df['Tweet_nonstop'] = test_df['Tweet_tokenized'].apply(lambda x: remove_stopwords(x,stopword))\ntest_df['Tweet_stemmed'] = test_df['Tweet_nonstop'].apply(lambda x: stemming(x))\ntest_df['Tweet_lemmatized'] = test_df['Tweet_nonstop'].apply(lambda x: lemmatizer(x))\ntest_df['Tweet_lemmatized'] = test_df[stemmed_or_lemmatized].apply(lambda x: ' '.join(str(e) for e in x))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:14:13.342125Z","iopub.execute_input":"2021-05-31T18:14:13.342532Z","iopub.status.idle":"2021-05-31T18:14:14.483206Z","shell.execute_reply.started":"2021-05-31T18:14:13.3425Z","shell.execute_reply":"2021-05-31T18:14:14.482186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:14:19.75672Z","iopub.execute_input":"2021-05-31T18:14:19.757052Z","iopub.status.idle":"2021-05-31T18:14:19.780391Z","shell.execute_reply.started":"2021-05-31T18:14:19.757022Z","shell.execute_reply":"2021-05-31T18:14:19.779473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initializing the training and validation datasets\n\nWe create a validation dataset from the training data with :\n<h4 align=\"center\">(90% train_df - 10% val_df)</h4>","metadata":{}},{"cell_type":"code","source":"# we create a validation dataset from the training data\nX_train, X_val, y_train, y_val = train_test_split(train_df[final_column], train_df[\"target\"], test_size=0.1, random_state=2021 )#stratify= train_df[\"target\"]","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:14:26.406845Z","iopub.execute_input":"2021-05-31T18:14:26.407249Z","iopub.status.idle":"2021-05-31T18:14:26.42919Z","shell.execute_reply.started":"2021-05-31T18:14:26.407191Z","shell.execute_reply":"2021-05-31T18:14:26.427271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### BERT TRANSFORMER ","metadata":{}},{"cell_type":"code","source":"from transformers import BertTokenizer\n\n# Load the BERT tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n\ndef text_preprocessing(text):\n    \"\"\"\n    - Remove entity mentions (eg. '@united')\n    - Correct errors (eg. '&amp;' to '&')\n    @param    text (str): a string to be processed.\n    @return   text (Str): the processed string.\n    \"\"\"\n    # Remove '@name'\n    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n\n    # Replace '&amp;' with '&'\n    text = re.sub(r'&amp;', '&', text)\n\n    # Remove trailing whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n\n    return text\n\n# Create a function to tokenize a set of texts\ndef preprocessing_for_bert(data):\n    \"\"\"Perform required preprocessing steps for pretrained BERT.\n    @param    data (np.array): Array of texts to be processed.\n    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n                  tokens should be attended to by the model.\n    \"\"\"\n    # Create empty lists to store outputs\n    input_ids = []\n    attention_masks = []\n\n    # For every sentence...\n    for sent in data:\n        # `encode_plus` will:\n        #    (1) Tokenize the sentence\n        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n        #    (3) Truncate/Pad sentence to max length\n        #    (4) Map tokens to their IDs\n        #    (5) Create attention mask\n        #    (6) Return a dictionary of outputs\n        encoded_sent = tokenizer.encode_plus(\n            text=text_preprocessing(sent),  # Preprocess sentence\n            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n            max_length=MAX_LEN,                  # Max length to truncate/pad\n            pad_to_max_length=True,         # Pad sentence to max length\n            #return_tensors='pt',           # Return PyTorch tensor\n            return_attention_mask=True      # Return attention mask\n            )\n        \n        # Add the outputs to the lists\n        input_ids.append(encoded_sent.get('input_ids'))\n        attention_masks.append(encoded_sent.get('attention_mask'))\n\n    # Convert lists to tensors\n    input_ids = torch.tensor(input_ids)\n    attention_masks = torch.tensor(attention_masks)\n\n    return input_ids, attention_masks","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:14:48.674464Z","iopub.execute_input":"2021-05-31T18:14:48.674784Z","iopub.status.idle":"2021-05-31T18:14:53.037115Z","shell.execute_reply.started":"2021-05-31T18:14:48.674755Z","shell.execute_reply":"2021-05-31T18:14:53.036288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Specify `MAX_LEN`\nMAX_LEN = 160\n\nprint('Tokenizing data...')\ntrain_inputs, train_masks = preprocessing_for_bert(X_train)\nval_inputs, val_masks = preprocessing_for_bert(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:14:56.713705Z","iopub.execute_input":"2021-05-31T18:14:56.714063Z","iopub.status.idle":"2021-05-31T18:15:04.425949Z","shell.execute_reply.started":"2021-05-31T18:14:56.714028Z","shell.execute_reply":"2021-05-31T18:15:04.425096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n\n# Convert other data types to torch.Tensor\ntrain_labels = torch.tensor(y_train.values)\nval_labels = torch.tensor(y_val.values)\n\n# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\nbatch_size = 32\n\n# Create the DataLoader for our training set\ntrain_data = TensorDataset(train_inputs, train_masks, train_labels)\ntrain_sampler = RandomSampler(train_data)\ntrain_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n\n# Create the DataLoader for our validation set\nval_data = TensorDataset(val_inputs, val_masks, val_labels)\nval_sampler = SequentialSampler(val_data)\nval_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:15:04.429691Z","iopub.execute_input":"2021-05-31T18:15:04.429976Z","iopub.status.idle":"2021-05-31T18:15:04.449637Z","shell.execute_reply.started":"2021-05-31T18:15:04.429948Z","shell.execute_reply":"2021-05-31T18:15:04.448643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport torch\nimport torch.nn as nn\nfrom transformers import BertModel\n\n# Create the BertClassfier class\nclass BertClassifier(nn.Module):\n    \"\"\"Bert Model for Classification Tasks.\n    \"\"\"\n    def __init__(self, freeze_bert=False):\n        \"\"\"\n        @param    bert: a BertModel object\n        @param    classifier: a torch.nn.Module classifier\n        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n        \"\"\"\n        super(BertClassifier, self).__init__()\n        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n        D_in, H, D_out = 768, 50, 3\n\n        # Instantiate BERT model\n        self.bert = BertModel.from_pretrained('bert-base-uncased')\n\n        # Instantiate an one-layer feed-forward classifier\n        self.classifier = nn.Sequential(\n            nn.Linear(D_in, H),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(H, D_out)\n        )\n\n        # Freeze the BERT model\n        if freeze_bert:\n            for param in self.bert.parameters():\n                param.requires_grad = False\n        \n    def forward(self, input_ids, attention_mask):\n        \"\"\"\n        Feed input to BERT and the classifier to compute logits.\n        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n                      max_length)\n        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n                      information with shape (batch_size, max_length)\n        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n                      num_labels)\n        \"\"\"\n        # Feed input to BERT\n        outputs = self.bert(input_ids=input_ids,\n                            attention_mask=attention_mask)\n        \n        # Extract the last hidden state of the token `[CLS]` for classification task\n        last_hidden_state_cls = outputs[0][:, 0, :]\n\n        # Feed input to classifier to compute logits\n        logits = self.classifier(last_hidden_state_cls)\n\n        return logits","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:15:09.431297Z","iopub.execute_input":"2021-05-31T18:15:09.431611Z","iopub.status.idle":"2021-05-31T18:15:09.470039Z","shell.execute_reply.started":"2021-05-31T18:15:09.431582Z","shell.execute_reply":"2021-05-31T18:15:09.469126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW, get_linear_schedule_with_warmup\n\ndef initialize_model(epochs=4):\n    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n    \"\"\"\n    # Instantiate Bert Classifier\n    bert_classifier = BertClassifier(freeze_bert=False)\n\n    # Tell PyTorch to run the model on GPU\n    bert_classifier.to(device)\n\n    # Create the optimizer\n    optimizer = AdamW(bert_classifier.parameters(),\n                      lr=1e-5,    # Default learning rate: 5e-5\n                      eps=1e-8    # Default epsilon value: 1e-8\n                      )\n\n    # Total number of training steps\n    total_steps = len(train_dataloader) * epochs\n\n    # Set up the learning rate scheduler\n    scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                num_warmup_steps=0, # Default value\n                                                num_training_steps=total_steps)\n    return bert_classifier, optimizer, scheduler","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:15:15.264293Z","iopub.execute_input":"2021-05-31T18:15:15.264609Z","iopub.status.idle":"2021-05-31T18:15:15.275184Z","shell.execute_reply.started":"2021-05-31T18:15:15.26458Z","shell.execute_reply":"2021-05-31T18:15:15.274335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import random\nimport time\nimport pickle\n\n# Specify loss function\nloss_fn = nn.CrossEntropyLoss()\n\ndef set_seed(seed_value=42):\n    \"\"\"Set seed for reproducibility.\n    \"\"\"\n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    torch.manual_seed(seed_value)\n    torch.cuda.manual_seed_all(seed_value)\n\ndef train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n    \"\"\"Train the BertClassifier model.\n    \"\"\"\n    # Start training loop\n    best_val = 0.\n    print(\"Start training...\\n\")\n    for epoch_i in range(epochs):\n        # =======================================\n        #               Training\n        # =======================================\n        # Print the header of the result table\n        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n        print(\"-\"*70)\n\n        # Measure the elapsed time of each epoch\n        t0_epoch, t0_batch = time.time(), time.time()\n\n        # Reset tracking variables at the beginning of each epoch\n        total_loss, batch_loss, batch_counts = 0, 0, 0\n\n        # Put the model into the training mode\n        model.train()\n\n        # For each batch of training data...\n        for step, batch in enumerate(train_dataloader):\n            batch_counts +=1\n            # Load batch to GPU\n            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n\n            # Zero out any previously calculated gradients\n            model.zero_grad()\n\n            # Perform a forward pass. This will return logits.\n            logits = model(b_input_ids, b_attn_mask)\n\n            # Compute loss and accumulate the loss values\n            loss = loss_fn(logits, b_labels)\n            batch_loss += loss.item()\n            total_loss += loss.item()\n\n            # Perform a backward pass to calculate gradients\n            loss.backward()\n\n            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n\n            # Update parameters and the learning rate\n            optimizer.step()\n            scheduler.step()\n\n            # Print the loss values and time elapsed for every 20 batches\n            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n                # Calculate time elapsed for 20 batches\n                time_elapsed = time.time() - t0_batch\n\n                # Print training results\n                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n                \n                # Reset batch tracking variables\n                batch_loss, batch_counts = 0, 0\n                t0_batch = time.time()\n\n        # Calculate the average loss over the entire training data\n        avg_train_loss = total_loss / len(train_dataloader)\n\n        print(\"-\"*70)\n        # =======================================\n        #               Evaluation\n        # =======================================\n        if evaluation == True:\n            # After the completion of each training epoch, measure the model's performance\n            # on our validation set.\n            val_loss, val_accuracy = evaluate(model, val_dataloader)\n            train_loss, train_accuracy = evaluate(model, train_dataloader)\n            \n            # Print performance over the entire training data\n            time_elapsed = time.time() - t0_epoch\n            \n            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n            print(\"-\"*70)\n        print(\"\\n\")\n        \n        if val_accuracy > best_val:\n            # save the model to disk\n            filename = 'finalized_model.sav'\n            pickle.dump(model, open(filename, 'wb'))\n            best_val = val_accuracy\n            print('Best validation accuracy reached. Saved model classifier.')\n        print('_'*50,\"\\n\")\n            \n    \n    print(\"Training complete!\")\n\n\ndef evaluate(model, val_dataloader):\n    \"\"\"After the completion of each training epoch, measure the model's performance\n    on our validation set.\n    \"\"\"\n    # Put the model into the evaluation mode. The dropout layers are disabled during\n    # the test time.\n    model.eval()\n\n    # Tracking variables\n    val_accuracy = []\n    val_loss = []\n#     all_probs = []\n#     all_preds = []\n\n    # For each batch in our validation set...\n    for batch in val_dataloader:\n        # Load batch to GPU\n        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n\n        # Compute logits\n        with torch.no_grad():\n            logits = model(b_input_ids, b_attn_mask)\n\n        # Compute loss\n        loss = loss_fn(logits, b_labels)\n        val_loss.append(loss.item())\n\n#         all_probs.append(logits)\n        # Get the predictions\n        preds = torch.argmax(logits, dim=1).flatten()\n#         all_preds.append(preds)\n\n        # Calculate the accuracy rate\n        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n        val_accuracy.append(accuracy)\n\n    # Compute the average accuracy and loss over the validation set.\n    val_loss = np.mean(val_loss)\n    val_accuracy = np.mean(val_accuracy)\n\n    return val_loss, val_accuracy #, torch.cat(all_preds), torch.cat(all_probs)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:15:26.571681Z","iopub.execute_input":"2021-05-31T18:15:26.572019Z","iopub.status.idle":"2021-05-31T18:15:26.589619Z","shell.execute_reply.started":"2021-05-31T18:15:26.571987Z","shell.execute_reply":"2021-05-31T18:15:26.5884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nset_seed(42)    # Set seed for reproducibility\nbert_classifier, optimizer, scheduler = initialize_model(epochs=5)\ntrain(bert_classifier, train_dataloader, val_dataloader, epochs=3, evaluation=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:15:33.897271Z","iopub.execute_input":"2021-05-31T18:15:33.897587Z","iopub.status.idle":"2021-05-31T18:40:09.101193Z","shell.execute_reply.started":"2021-05-31T18:15:33.89756Z","shell.execute_reply":"2021-05-31T18:40:09.100279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nfrom sklearn.metrics import roc_auc_score\ndef evaluate_with_auc(model, dataloader):\n    \"\"\"After the completion of each training epoch, measure the model's performance\n    on our validation set.\n    \"\"\"\n    # Put the model into the evaluation mode. The dropout layers are disabled during\n    # the test time.\n    model.eval()\n\n    # Tracking variables\n    output_accuracy = []\n    output_loss = []\n    all_logits = []\n    all_b_labels = []\n#     all_probs = []\n#     all_preds = []\n\n    # For each batch in our validation set...\n    for batch in dataloader:\n        # Load batch to GPU\n        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n\n        # Compute logits\n        with torch.no_grad():\n            logits = model(b_input_ids, b_attn_mask)\n\n        # Compute loss\n        loss = loss_fn(logits, b_labels)\n        output_loss.append(loss.item())\n\n#         all_probs.append(logits)\n        # Get the predictions\n        preds = torch.argmax(logits, dim=1).flatten()\n#         all_preds.append(preds)\n\n        # Calculate the accuracy rate\n        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n        output_accuracy.append(accuracy)\n        \n        all_logits.append(logits)\n        all_b_labels.append(b_labels)\n\n        \n    # Concatenate logits from each batch\n    all_logits = torch.cat(all_logits, dim=0)\n    \n    # Apply softmax to calculate probabilities\n    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n    \n    all_b_labels = torch.cat(all_b_labels, dim=0)\n    b_labels_dummies = pd.get_dummies(all_b_labels.cpu().numpy())\n    #print(b_labels_dummies)\n    \n    output_auc = roc_auc_score(b_labels_dummies,probs,multi_class=\"ovo\",average='macro')\n        \n    # Compute the average accuracy and loss over the validation set.\n    output_loss = np.mean(output_loss)\n    output_accuracy = np.mean(output_accuracy)\n\n    return output_loss, output_accuracy, output_auc, b_labels_dummies,probs #, torch.cat(all_preds), torch.cat(all_probs)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:45:30.038091Z","iopub.execute_input":"2021-05-31T18:45:30.038437Z","iopub.status.idle":"2021-05-31T18:45:30.048554Z","shell.execute_reply.started":"2021-05-31T18:45:30.03841Z","shell.execute_reply":"2021-05-31T18:45:30.047417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Y_val_dummies = pd.get_dummies(y_val.values)\nY_train_dummies = pd.get_dummies(y_train.values)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:45:37.785916Z","iopub.execute_input":"2021-05-31T18:45:37.786271Z","iopub.status.idle":"2021-05-31T18:45:37.796456Z","shell.execute_reply.started":"2021-05-31T18:45:37.786234Z","shell.execute_reply":"2021-05-31T18:45:37.795562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loss, train_accuracy, train_auc, b_labels_train_dum, train_probs = evaluate_with_auc(bert_classifier,train_dataloader)\nval_loss, val_accuracy, val_auc , b_labels_val_dum, val_probs = evaluate_with_auc(bert_classifier,val_dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:45:42.050272Z","iopub.execute_input":"2021-05-31T18:45:42.050589Z","iopub.status.idle":"2021-05-31T18:47:47.897776Z","shell.execute_reply.started":"2021-05-31T18:45:42.05056Z","shell.execute_reply":"2021-05-31T18:47:47.896969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"(train_loss = {:.4f}, train_accuracy = {:.4f})\".format(train_loss, train_accuracy/100))\nprint(\"\\n(train_loss = {:.4f},train_auc = {:.4f})\".format(train_loss, train_auc))\n\nprint(\"\\n(val_loss = {:.4f}, val_accuracy = {:.4f})\".format(val_loss, val_accuracy/100))\nprint(\"\\n(val_loss = {:.4f}, val_auc = {:.4f})\".format(val_loss, val_auc))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:47:50.848483Z","iopub.execute_input":"2021-05-31T18:47:50.848805Z","iopub.status.idle":"2021-05-31T18:47:50.854709Z","shell.execute_reply.started":"2021-05-31T18:47:50.848775Z","shell.execute_reply":"2021-05-31T18:47:50.85385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### predict on training set and validation set","metadata":{}},{"cell_type":"code","source":"train_prediction = train_probs.argmax(axis=1)\nval_prediction = val_probs.argmax(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:48:09.065215Z","iopub.execute_input":"2021-05-31T18:48:09.065621Z","iopub.status.idle":"2021-05-31T18:48:09.070749Z","shell.execute_reply.started":"2021-05-31T18:48:09.065583Z","shell.execute_reply":"2021-05-31T18:48:09.069754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\n\ndef bert_predict(model, test_dataloader):\n    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n    on the test set.\n    \"\"\"\n    # Put the model into the evaluation mode. The dropout layers are disabled during\n    # the test time.\n    model.eval()\n\n    all_logits = []\n\n    # For each batch in our test set...\n    for batch in test_dataloader:\n        # Load batch to GPU\n        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n\n        # Compute logits\n        with torch.no_grad():\n            logits = model(b_input_ids, b_attn_mask)\n        all_logits.append(logits)\n    \n    # Concatenate logits from each batch\n    all_logits = torch.cat(all_logits, dim=0)\n    \n    # Apply softmax to calculate probabilities\n    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n    \n    return probs.argmax(axis=1), probs\n\nbert_classifier = pickle.load(open('finalized_model.sav', 'rb'))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:48:17.427587Z","iopub.execute_input":"2021-05-31T18:48:17.427973Z","iopub.status.idle":"2021-05-31T18:48:18.035583Z","shell.execute_reply.started":"2021-05-31T18:48:17.427917Z","shell.execute_reply":"2021-05-31T18:48:18.0347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom scipy import interp\n\nfrom  sklearn.metrics import precision_recall_fscore_support, roc_curve, auc, accuracy_score\nfrom sklearn.preprocessing import LabelBinarizer\n\ndef class_report(y_true, y_pred, y_score=None, average='macro'):\n    '''\n    Inputs:\n        y_true: the actual labels\n        y_pred: the predicted labels\n    Output:\n        accuracy, precision, recall, f1-score, support (actual nb), pred (predicted nb) for multiclass pb\n    '''\n    if y_true.shape != y_pred.shape:\n        print(\"Error! y_true %s is not the same shape as y_pred %s\" % (\n              y_true.shape,\n              y_pred.shape)\n        )\n        return\n\n    lb = LabelBinarizer()\n\n    if len(y_true.shape) == 1:\n        lb.fit(y_true)\n\n    #Value counts of predictions\n    labels, cnt = np.unique(\n        y_pred,\n        return_counts=True)\n    n_classes = len(labels)\n    pred_cnt = pd.Series(cnt, index=labels)\n\n    metrics_summary = precision_recall_fscore_support(\n            y_true=y_true,\n            y_pred=y_pred,\n            labels=labels)\n\n    avg = list(precision_recall_fscore_support(\n            y_true=y_true, \n            y_pred=y_pred,\n            average='weighted'))\n\n    metrics_sum_index = ['precision', 'recall', 'f1-score', 'support']\n    class_report_df = pd.DataFrame(\n        list(metrics_summary),\n        index=metrics_sum_index,\n        columns=labels)\n\n    support = class_report_df.loc['support']\n    total = support.sum() \n    class_report_df['avg / total'] = avg[:-1] + [total]\n\n    class_report_df = class_report_df.T\n    class_report_df['pred'] = pred_cnt\n    class_report_df['pred'].iloc[-1] = total\n\n    if not (y_score is None):\n        fpr = dict()\n        tpr = dict()\n        roc_auc = dict()\n        for label_it, label in enumerate(labels):\n            fpr[label], tpr[label], _ = roc_curve(\n                (y_true == label).astype(int), \n                y_score[:, label_it])\n\n            roc_auc[label] = auc(fpr[label], tpr[label])\n\n        if average == 'micro':\n            if n_classes <= 2:\n                fpr[\"avg / total\"], tpr[\"avg / total\"], _ = roc_curve(\n                    lb.transform(y_true).ravel(), \n                    y_score[:, 1].ravel())\n            else:\n                fpr[\"avg / total\"], tpr[\"avg / total\"], _ = roc_curve(\n                        lb.transform(y_true).ravel(), \n                        y_score.ravel())\n\n            roc_auc[\"avg / total\"] = auc(\n                fpr[\"avg / total\"], \n                tpr[\"avg / total\"])\n\n        elif average == 'macro':\n            # First aggregate all false positive rates\n            all_fpr = np.unique(np.concatenate([\n                fpr[i] for i in labels]\n            ))\n\n            # Then interpolate all ROC curves at this points\n            mean_tpr = np.zeros_like(all_fpr)\n            for i in labels:\n                mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n            # Finally average it and compute AUC\n            mean_tpr /= n_classes\n\n            fpr[\"macro\"] = all_fpr\n            tpr[\"macro\"] = mean_tpr\n\n            roc_auc[\"avg / total\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n        class_report_df['AUC'] = pd.Series(roc_auc)\n        \n    class_report_df.rename(index={0:'-1 (negative)',1:'0 (neutral)',2:'1 (positive)'}, inplace=True)\n    class_report_df[\"support\"] = class_report_df[\"support\"].astype(int)\n    class_report_df[\"pred\"] = class_report_df[\"pred\"].astype(int)\n#     values = confusion_matrix(y_true, y_pred, normalize=\"all\").diagonal()\n#     class_report_df.insert(0, 'accuracy', pd.DataFrame(np.append(values, np.mean(values))).values)\n    return class_report_df","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:48:35.743902Z","iopub.execute_input":"2021-05-31T18:48:35.744285Z","iopub.status.idle":"2021-05-31T18:48:35.763553Z","shell.execute_reply.started":"2021-05-31T18:48:35.744251Z","shell.execute_reply":"2021-05-31T18:48:35.762286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"For the training:\\n\")\nclass_report(np.array(b_labels_train_dum).argmax(axis=1), train_prediction)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:48:43.606301Z","iopub.execute_input":"2021-05-31T18:48:43.606612Z","iopub.status.idle":"2021-05-31T18:48:43.639485Z","shell.execute_reply.started":"2021-05-31T18:48:43.606584Z","shell.execute_reply":"2021-05-31T18:48:43.63853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import itertools\nfrom sklearn.metrics import confusion_matrix\n    \ndef plot_confusion_matrix(cm, classes,title,normalize=False,cmap=plt.cm.Greens):\n    plt.subplots(figsize=(10,4))\n    ### Confusion Matrix (from the challenge AML made in group)\n    plt.subplot(1, 2, 1)\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() - 500.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    return plt.show()\n\ncm=confusion_matrix(np.array(b_labels_train_dum).argmax(axis=1), train_prediction)\nplot_confusion_matrix(cm, classes=[\"negative\",\"neutral\",\"positive\"],title='Confusion matrix for training')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:49:21.583582Z","iopub.execute_input":"2021-05-31T18:49:21.583898Z","iopub.status.idle":"2021-05-31T18:49:21.892622Z","shell.execute_reply.started":"2021-05-31T18:49:21.583869Z","shell.execute_reply":"2021-05-31T18:49:21.891841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"For the validation:\\n\")\nclass_report(np.array(b_labels_val_dum).argmax(axis=1), val_prediction)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:49:52.947551Z","iopub.execute_input":"2021-05-31T18:49:52.947876Z","iopub.status.idle":"2021-05-31T18:49:52.97308Z","shell.execute_reply.started":"2021-05-31T18:49:52.947847Z","shell.execute_reply":"2021-05-31T18:49:52.972306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cm = confusion_matrix(np.array(b_labels_val_dum).argmax(axis=1), val_prediction)\nplot_confusion_matrix(cm, classes=[\"negative\",\"neutral\",\"positive\"],title='Confusion matrix for validation')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:49:57.914443Z","iopub.execute_input":"2021-05-31T18:49:57.914757Z","iopub.status.idle":"2021-05-31T18:49:58.196927Z","shell.execute_reply.started":"2021-05-31T18:49:57.914727Z","shell.execute_reply":"2021-05-31T18:49:58.196164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Creating a submission\ntest_inputs, test_masks = preprocessing_for_bert(test_df[final_column].values)\ntest_data = TensorDataset(test_inputs, test_masks)\ntest_sampler = SequentialSampler(test_data)\ntest_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)\n\ntest_predictions_nb, _ = bert_predict(bert_classifier,test_dataloader)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_predictions_nb-1 # to put the right target\nsubmission_df.to_csv('TA_baseline_NB.csv', index=False)\nsubmission_df[final_column] = test_df[final_column]\nsubmission_df[\"selected_text\"] = test_df[\"selected_text\"]\nsubmission_df.to_csv('To_analyse.csv', index=False)\n#submission_df","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:50:03.448146Z","iopub.execute_input":"2021-05-31T18:50:03.448475Z","iopub.status.idle":"2021-05-31T18:50:18.235179Z","shell.execute_reply.started":"2021-05-31T18:50:03.448447Z","shell.execute_reply":"2021-05-31T18:50:18.23408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raise SystemExit(\"Exit from script\") # to stop the running here ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:50:18.23683Z","iopub.execute_input":"2021-05-31T18:50:18.237421Z","iopub.status.idle":"2021-05-31T18:50:18.243034Z","shell.execute_reply.started":"2021-05-31T18:50:18.237383Z","shell.execute_reply":"2021-05-31T18:50:18.241837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Bag of Words ","metadata":{}},{"cell_type":"markdown","source":"### LSTM","metadata":{}},{"cell_type":"code","source":"import re\nimport gensim\nfrom nltk.tokenize.treebank import TreebankWordDetokenizer\nfrom keras.preprocessing.text import Tokenizer\n\n# bag of words using Keras\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras import regularizers\nfrom tqdm import tqdm\n\n\nmax_words = 5000\nmax_len = 200\n\ndef Tokenize(data):\n    tokenizer = Tokenizer(num_words=max_words)\n    tokenizer.fit_on_texts(data)\n    sequences = tokenizer.texts_to_sequences(data)\n    tweets = pad_sequences(sequences, maxlen=max_len)\n    return tweets\n\n\ndef inverse_dummy_function(val_pred_lstm):\n    output = []\n    for i in tqdm(range(len(val_pred_lstm))):\n        #print(val_pred_model1[i])\n        if (val_pred_lstm[i] == [0,1,0] ).all():\n            output.append(0)\n        elif (val_pred_lstm[i] == [1,0,0]).all():\n             output.append(-1)\n        elif (val_pred_lstm[i] == [0,0,1]).all():\n             output.append(1)\n        else :\n            print('error')\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:50:45.083391Z","iopub.execute_input":"2021-05-31T18:50:45.083711Z","iopub.status.idle":"2021-05-31T18:50:45.091411Z","shell.execute_reply.started":"2021-05-31T18:50:45.083682Z","shell.execute_reply":"2021-05-31T18:50:45.090582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#put the right target\ntarget_conversion = {\n    0: -1,\n    1: 0,\n    2: 1,\n    \n}\n\ny_train_labels = y_train.map(target_conversion)\ny_val_labels = y_val.map(target_conversion)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:50:58.176485Z","iopub.execute_input":"2021-05-31T18:50:58.176806Z","iopub.status.idle":"2021-05-31T18:50:58.186507Z","shell.execute_reply.started":"2021-05-31T18:50:58.176774Z","shell.execute_reply":"2021-05-31T18:50:58.185701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#one-hot encoding\nY_train_dummies= pd.get_dummies(y_train_labels).values\nY_val_dummies= pd.get_dummies(y_val_labels).values\n\n#Adapting input values for LSTM\nX_train_tokenized = Tokenize(X_train)\nX_val_tokenized = Tokenize(X_val)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:51:05.497429Z","iopub.execute_input":"2021-05-31T18:51:05.497759Z","iopub.status.idle":"2021-05-31T18:51:06.094311Z","shell.execute_reply.started":"2021-05-31T18:51:05.497721Z","shell.execute_reply":"2021-05-31T18:51:06.093444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras import layers\nfrom keras import regularizers\nfrom keras import backend as K\nfrom keras.layers import Embedding\nfrom keras.callbacks import ModelCheckpoint\n# This returns the LSTM model in Keras.\nvocabulary_size = max_words #= 5000\ndef get_keras_model(lstm_units,\n                    neurons_dense,\n                    dropout_rate,\n                    embedding_size,\n                    max_text_len):\n    # define the layers.\n    \n    inputs = tf.keras.Input(shape=(max_text_len,))\n    x = layers.Embedding(vocabulary_size, embedding_size)(inputs)\n    x = layers.LSTM(units=lstm_units)(x)\n    x = layers.Dense(neurons_dense, activation=\"relu\")(x)\n    x = layers.Dropout(dropout_rate)(x)\n\n    outputs = layers.Dense(3, activation='softmax')(x)\n    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:51:14.238362Z","iopub.execute_input":"2021-05-31T18:51:14.238685Z","iopub.status.idle":"2021-05-31T18:51:14.248822Z","shell.execute_reply.started":"2021-05-31T18:51:14.238655Z","shell.execute_reply":"2021-05-31T18:51:14.248037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntf.keras.backend.clear_session()\n\n\nmax_text_len = 663\nmodel_lstm_cv = get_keras_model(8,\n                        47,\n                        0.052,\n                        58,\n                        max_text_len)\n\noptimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n\n# Specify the training configuration.\nmodel_lstm_cv.compile(optimizer=optimizer,\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n\n#tokenizer0 = Tokenizer(num_words=vocabulary_size)\n#tokenizer0.fit_on_texts(data_df['Tweet_lemmatized'].values)\n#X_train_seq0 = tokenizer0.texts_to_sequences(data_df['Tweet_lemmatized'].values)\nX_train_seq0_padded = pad_sequences(X_train_tokenized, maxlen=max_text_len)\nX_val_seq0_padded = pad_sequences(X_val_tokenized, maxlen=max_text_len)\n#y_train0 = df_train0['sentiment'].values\n\n# fit the model using a 20% validation set.\ncheckpoint1 = ModelCheckpoint(\"best_model1.hdf5\", monitor='val_accuracy', verbose=1,save_best_only=True, mode='auto', period=1,save_weights_only=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:51:25.865705Z","iopub.execute_input":"2021-05-31T18:51:25.866057Z","iopub.status.idle":"2021-05-31T18:51:26.855974Z","shell.execute_reply.started":"2021-05-31T18:51:25.866024Z","shell.execute_reply":"2021-05-31T18:51:26.855158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_lstm_cv.fit(x=X_train_seq0_padded,\n          y=Y_train_dummies,\n          batch_size=50, \n          epochs=3,\n          validation_data=(X_val_seq0_padded, Y_val_dummies),\n          callbacks=[checkpoint1])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T18:51:54.60858Z","iopub.execute_input":"2021-05-31T18:51:54.608898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### evaluating the model","metadata":{}},{"cell_type":"code","source":"#validation\nval_pred_model_lstm_cv_prob = model_lstm_cv.predict(X_val_seq0_padded)\nval_pred_model_lstm_cv = (val_pred_model_lstm_cv_prob == val_pred_model_lstm_cv_prob.max(axis=1)[:,None]).astype(int)\nval_pred_lstm_cv = inverse_dummy_function(val_pred_model_lstm_cv)\n\n#training\ntrain_pred_model_lstm_cv_prob = model_lstm_cv.predict(X_train_seq0_padded)\ntrain_pred_model_lstm_cv = (train_pred_model_lstm_cv_prob == train_pred_model_lstm_cv_prob.max(axis=1)[:,None]).astype(int)\ntrain_pred_lstm_cv = inverse_dummy_function(train_pred_model_lstm_cv)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:38:31.063036Z","iopub.execute_input":"2021-05-31T14:38:31.063367Z","iopub.status.idle":"2021-05-31T14:38:40.4444Z","shell.execute_reply.started":"2021-05-31T14:38:31.063337Z","shell.execute_reply":"2021-05-31T14:38:40.443315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy_model = (val_pred_lstm_cv == y_val_labels.values).mean()\nprint('The accuracy of our LSTM classifier is: {:.2f}%'.format(accuracy_model*100))\n\naccuracy_model = (train_pred_lstm_cv == y_train_labels.values).mean()\nprint('The accuracy of our LSTM classifier is: {:.2f}%'.format(accuracy_model*100))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:38:40.445829Z","iopub.execute_input":"2021-05-31T14:38:40.446173Z","iopub.status.idle":"2021-05-31T14:38:40.456954Z","shell.execute_reply.started":"2021-05-31T14:38:40.446129Z","shell.execute_reply":"2021-05-31T14:38:40.455832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\n\n#roc_auc_score(np.array(val_pred_lstm_cv), y_prob, multi_class=\"ovo\",\n#                                  average=\"macro\")\nauc_lstm_val = roc_auc_score(Y_val_dummies,val_pred_model_lstm_cv_prob,multi_class=\"ovo\")\nauc_lstm_train = roc_auc_score(Y_train_dummies, train_pred_model_lstm_cv_prob, multi_class=\"ovo\")\nprint('The validation auc of our LSTM classifier is: {:.2f}'.format(auc_lstm_val))\nprint('The training auc of of our LSTM classifier is: {:.2f}'.format(auc_lstm_train))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:38:55.942711Z","iopub.execute_input":"2021-05-31T14:38:55.943049Z","iopub.status.idle":"2021-05-31T14:38:55.967773Z","shell.execute_reply.started":"2021-05-31T14:38:55.94302Z","shell.execute_reply":"2021-05-31T14:38:55.966855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### submitting LSTM model file","metadata":{}},{"cell_type":"code","source":"X_test_tokenized = Tokenize(test_df[final_column].values)\n\nX_test_seq0_padded = pad_sequences(X_test_tokenized, maxlen=max_text_len)\ntest_pred_lstm = model_lstm_cv.predict(X_test_seq0_padded)\n\ntest_pred_lstm = (test_pred_lstm == test_pred_lstm.max(axis=1)[:,None]).astype(int)\ntest_pred_lstm_final = inverse_dummy_function(test_pred_lstm)\n\nsubmission_df = pd.DataFrame()\nsubmission_df['textID'] = test_df['textID']\nsubmission_df['sentiment'] = test_pred_lstm_final\nsubmission_df.to_csv('LSTM_sumbmission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:39:03.371987Z","iopub.execute_input":"2021-05-31T14:39:03.372302Z","iopub.status.idle":"2021-05-31T14:39:04.558841Z","shell.execute_reply.started":"2021-05-31T14:39:03.372273Z","shell.execute_reply":"2021-05-31T14:39:04.55807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### K-NN & RandomForest & MultiLayerPerceptron","metadata":{}},{"cell_type":"code","source":"# preparation of data :\n\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\nimport xgboost as xgb\n\ncountV = CountVectorizer() # Bag Of Words\ncountV.fit_transform(X_train) # Fit the dictionnary\n\n\ndef train_test_model(model,train_df,test_df,y,y_test,model_name) : \n    model_bow = Pipeline([('countV_bayes',countV),('model',model)])\n    model_bow.fit(train_df,y)\n    probas_train = model_bow.predict_proba(train_df)\n    probas_test = model_bow.predict_proba(test_df)\n    y_pred_train = model_bow.predict(train_df)\n    y_pred_test = model_bow.predict(test_df)\n    auc_train = roc_auc_score(pd.get_dummies(y).values, probas_train, multi_class=\"ovo\")\n    auc_test = roc_auc_score(pd.get_dummies(y_test).values, probas_test, multi_class=\"ovo\")\n    accuracy_train = np.mean(y_pred_train == y)\n    accuracy_test = np.mean(y_pred_test == y_test)\n    #f1_train = f1_score(y_pred_train,y)\n    #f1_test = f1_score(y_pred_test,y_test)\n    \n    print(\"For training score Using \"+ model_name +\" we have {} as auc score, {} as accuracy\".format(auc_train,accuracy_train))\n    print(\"For testing score Using \" + model_name +\" we have {} as auc score, {} as accuracy\".format(auc_test,accuracy_test))\n    print(\"END##############################\")\n    \ntrain_test_model(RandomForestClassifier(n_estimators=300,max_depth=40),X_train,X_val,y_train,y_val,\"Random Forest\")\ntrain_test_model(KNeighborsClassifier(n_neighbors=4),X_train,X_val,y_train,y_val,\"K - nearest Neighbors\")\ntrain_test_model(MLPClassifier(solver='lbfgs',\n                                         alpha=1e-5,\n                                         hidden_layer_sizes=(300,300,300),\n                                         random_state=1),X_train,X_val,y_train,y_val,\"MLP\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T15:49:43.909217Z","iopub.execute_input":"2021-05-31T15:49:43.909561Z","iopub.status.idle":"2021-05-31T15:56:41.205028Z","shell.execute_reply.started":"2021-05-31T15:49:43.909527Z","shell.execute_reply":"2021-05-31T15:56:41.201659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Word2Vec","metadata":{}},{"cell_type":"markdown","source":"### K-NN & RandomForest & MultiLayerPerceptron","metadata":{}},{"cell_type":"code","source":"## Word2Vec \n\nimport gensim\n\ntweets = X_train.apply(lambda x: tokenization(x.lower())).values#.apply(lambda x: lemmatizer(x))#.apply(lambda x: tokenization(x.lower()))\n\nmodel_w2v = gensim.models.Word2Vec(\n            tweets,\n            vector_size=663, # desired no. of features/independent variables\n            window=5, # context window size\n            min_count=2, # Ignores all words with total frequency lower than 2.                                  \n            sg = 1, # 1 for skip-gram model\n            hs = 0,\n            negative = 10, # for negative sampling\n            workers= 32, # no.of cores\n            seed = 34\n) \n\nmodel_w2v.train(tweets, total_examples= len(tweets), epochs=20)\n\ndef word_vector(tokens, size):\n    vec = np.zeros(size).reshape((1, size))\n    count = 0\n    for word in tokens:\n        try:\n            vec += model_w2v.wv[word].reshape((1, size))\n            count += 1.\n        except KeyError:  # handling the case where the token is not in vocabulary\n            continue\n    if count != 0:\n        vec /= count\n    return vec\n\ntrain_size = len(tweets)\ntrain_arrays = np.zeros((train_size, 663))\n\ndef wordLists(data) :\n    size = len(data)\n    output = np.zeros((size, 663))\n    for i in range(size):\n        output[i,:] = word_vector(data[i], 663)\n    return output ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:16:25.122197Z","iopub.execute_input":"2021-05-31T16:16:25.122514Z","iopub.status.idle":"2021-05-31T16:16:44.819067Z","shell.execute_reply.started":"2021-05-31T16:16:25.122486Z","shell.execute_reply":"2021-05-31T16:16:44.818221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_wordw2v = wordLists(X_train.apply(lambda x: tokenization(x.lower())).values)\nval_wordw2v = wordLists(X_val.apply(lambda x: tokenization(x.lower())).values)\ntest_wordw2v = wordLists(test_df.Tweet_stemmed.values)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:19:11.928022Z","iopub.execute_input":"2021-05-31T16:19:11.928339Z","iopub.status.idle":"2021-05-31T16:19:12.902143Z","shell.execute_reply.started":"2021-05-31T16:19:11.928311Z","shell.execute_reply":"2021-05-31T16:19:12.901246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_test_model_W2V(model,train_df,test_df_,y,y_test,model_name) : \n    \n    model_w2v = model\n    model_w2v.fit(train_df,y)\n    probas_train = model_w2v.predict_proba(train_df)\n    probas_test = model_w2v.predict_proba(test_df_)\n    y_pred_train = model_w2v.predict(train_df)\n    y_pred_test = model_w2v.predict(test_df_)\n    auc_train = roc_auc_score(pd.get_dummies(y).values, probas_train, multi_class=\"ovo\")\n    auc_test = roc_auc_score(pd.get_dummies(y_test).values, probas_test, multi_class=\"ovo\")\n    accuracy_train = np.mean(y_pred_train == y)\n    accuracy_test = np.mean(y_pred_test == y_test)\n\n\n    print(\"For training score Using \"+ model_name +\" we have {} as auc score, {} as accuracy\".format(auc_train,accuracy_train))\n    print(\"For testing score Using \" + model_name +\" we have {} as auc score, {} as accuracy\".format(auc_test,accuracy_test))\n    print(\"END##############################\")\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T16:51:50.553745Z","iopub.execute_input":"2021-05-31T16:51:50.554107Z","iopub.status.idle":"2021-05-31T16:51:50.560766Z","shell.execute_reply.started":"2021-05-31T16:51:50.554073Z","shell.execute_reply":"2021-05-31T16:51:50.559963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_test_model_W2V(RandomForestClassifier(n_estimators=300,max_depth=40),train_wordw2v,val_wordw2v,y_train,y_val,\"Random Forest\")\ntrain_test_model_W2V(KNeighborsClassifier(n_neighbors=4),train_wordw2v,val_wordw2v,y_train,y_val,\"K - nearest Neighbors\")\nmlp = train_test_model_W2V(MLPClassifier(solver='lbfgs',\n                                         alpha=1e-5,\n                                         hidden_layer_sizes=(300,300,300),\n                                         random_state=1),train_wordw2v,val_wordw2v,y_train,y_val,\"MLP\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T17:07:16.378053Z","iopub.execute_input":"2021-05-31T17:07:16.378473Z","iopub.status.idle":"2021-05-31T17:15:47.986114Z","shell.execute_reply.started":"2021-05-31T17:07:16.378435Z","shell.execute_reply":"2021-05-31T17:15:47.985143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LSTM ","metadata":{}},{"cell_type":"code","source":"model_lstm_cv.fit(x=X_train_seq0_padded,\n          y=Y_train_dummies,\n          batch_size=50, \n          epochs=3,\n          validation_data=(X_val_seq0_padded, Y_val_dummies),\n          callbacks=[checkpoint1])\n\n#validation\nval_pred_model_lstm_cv_prob = model_lstm_cv.predict(X_val_seq0_padded)\nval_pred_model_lstm_cv = (val_pred_model_lstm_cv_prob == val_pred_model_lstm_cv_prob.max(axis=1)[:,None]).astype(int)\nval_pred_lstm_cv = inverse_dummy_function(val_pred_model_lstm_cv)\n\n#training\ntrain_pred_model_lstm_cv_prob = model_lstm_cv.predict(X_train_seq0_padded)\ntrain_pred_model_lstm_cv = (train_pred_model_lstm_cv_prob == train_pred_model_lstm_cv_prob.max(axis=1)[:,None]).astype(int)\ntrain_pred_lstm_cv = inverse_dummy_function(train_pred_model_lstm_cv)\n\naccuracy_model = (val_pred_lstm_cv == y_val_labels.values).mean()\nprint('The accuracy of our LSTM classifier is: {:.2f}%'.format(accuracy_model*100))\n\naccuracy_model = (train_pred_lstm_cv == y_train_labels.values).mean()\nprint('The accuracy of our LSTM classifier is: {:.2f}%'.format(accuracy_model*100))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:19:42.219066Z","iopub.status.idle":"2021-05-31T14:19:42.219718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import f1_score\n\n#roc_auc_score(np.array(val_pred_lstm_cv), y_prob, multi_class=\"ovo\",\n#                                  average=\"macro\")\nauc_lstm_val = roc_auc_score(Y_val_dummies,val_pred_model_lstm_cv_prob,multi_class=\"ovo\")\nauc_lstm_train = roc_auc_score(Y_train_dummies, train_pred_model_lstm_cv_prob, multi_class=\"ovo\")\nprint('The validation auc of our LSTM classifier is: {:.2f}'.format(auc_lstm_val))\nprint('The training auc of of our LSTM classifier is: {:.2f}'.format(auc_lstm_train))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:19:42.220947Z","iopub.status.idle":"2021-05-31T14:19:42.221574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Conclusion \nTo conclude, through this challenge we discovered different kinds of embedding techniques such as word2vec, bag-of-words and bert. We learned what kind of basic preprocessing one can do on typescripts data. And by comparing different models based on the accuracy and the auc we chose the transformer with the bert model. For our submissions we submit the outputs of the transformer with bert. Natural language is a large domain and we saw how difficult it was to tune models and preprocess the data in order to reach good auc and accuracy. For future work we could enhance our model to detect the words based on   which, it classifies the sentiment as positive, negative or neutral.\n","metadata":{}}]}